
  0%|                                                                                                                                                                                                                   | 0/257 [00:03<?, ?it/s]
Traceback (most recent call last):
  File "/home/barry/Desktop/uni/dbl2/JBG040-Group19/VIT/hope.py", line 128, in <module>
    output = model(X)             # forward pass
  File "/home/barry/anaconda3/envs/dbl2/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/barry/anaconda3/envs/dbl2/lib/python3.10/site-packages/timm/models/vision_transformer.py", line 549, in forward
    x = self.forward_features(x)
  File "/home/barry/anaconda3/envs/dbl2/lib/python3.10/site-packages/timm/models/vision_transformer.py", line 538, in forward_features
    x = self.blocks(x)
  File "/home/barry/anaconda3/envs/dbl2/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/barry/anaconda3/envs/dbl2/lib/python3.10/site-packages/torch/nn/modules/container.py", line 204, in forward
    input = module(input)
  File "/home/barry/anaconda3/envs/dbl2/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/barry/anaconda3/envs/dbl2/lib/python3.10/site-packages/timm/models/vision_transformer.py", line 269, in forward
    x = x + self.drop_path2(self.ls2(self.mlp(self.norm2(x))))
  File "/home/barry/anaconda3/envs/dbl2/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/barry/anaconda3/envs/dbl2/lib/python3.10/site-packages/timm/models/layers/mlp.py", line 28, in forward
    x = self.act(x)
  File "/home/barry/anaconda3/envs/dbl2/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1194, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/barry/anaconda3/envs/dbl2/lib/python3.10/site-packages/torch/nn/modules/activation.py", line 684, in forward
    return F.gelu(input, approximate=self.approximate)
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 76.00 MiB (GPU 0; 5.80 GiB total capacity; 4.36 GiB already allocated; 58.31 MiB free; 4.53 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF